{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Regression.ipynb_Functional_api",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H7tXS96Jc5I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import fetch_california_housing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_z6uTjQKIOz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xN_85UKlKPcY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgVb-gPrKYtP",
        "colab_type": "code",
        "outputId": "09ffb208-5353-40d9-93d9-254d0941a861",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "housing = fetch_california_housing()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to /root/scikit_learn_data\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLP8Yrd5K17n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_full, X_test, y_train_full, y_test = train_test_split( housing.data, housing.target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5o0MtUmLYMD",
        "colab_type": "text"
      },
      "source": [
        "**WHY SPLITTING TRAIN FURTHER**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0Re8j1rK8cI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split( X_train_full, y_train_full)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzoeUqaULBdy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler = StandardScaler()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDiAOdS5LdrK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = scaler.fit_transform(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3WCg-YrLgoS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_valid = scaler.transform(X_valid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rh-uYzdGLlnO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HhgO_JSOwew",
        "colab_type": "code",
        "outputId": "0f95fac9-70bd-4012-ba0d-877d9a3aa741",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape[1:]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71dfTGoqOzzR",
        "colab_type": "code",
        "outputId": "a2d954c5-9efa-4e72-baa4-d70165adffc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11610, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8W1-f3EVPbC4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xJqlAMtPxls",
        "colab_type": "text"
      },
      "source": [
        "Using the Sequential API to build, train, evaluate, and use a regression MLP to make predictions is quite similar to what we did for classification. The main differences are the fact that the output layer has a single neuron (since we only want to predict a single value) and uses no activation function, and the loss function is the mean squared error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAx31XhHLrPl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ = keras.layers.Input(shape=X_train.shape[1:]) \n",
        "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_) \n",
        "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1) \n",
        "concat = keras.layers.Concatenate()([input_, hidden2]) \n",
        "output = keras.layers.Dense(1)(concat) \n",
        "model = keras.Model(inputs=[input_], outputs=[output])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pui21ka82u9k",
        "colab_type": "text"
      },
      "source": [
        "**NOTE NONE**\n",
        "\n",
        "In keras, a None dimension means that it can be any scalar number, so that you use this model to infer on an arbitrarily long input. This dimension does not affect the size of the network, it just denotes that you are free to select the length (number of samples) of your input during testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJzEslPu19w3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cef43370-dea8-4573-f9d5-8a2d2cda1e69"
      },
      "source": [
        "input_.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 8])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tftMnXH2AYy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "505635b7-be24-46d8-ee46-f910b4f64332"
      },
      "source": [
        "hidden2.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 30])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6MM2MhK2HLM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ff6a7345-4a12-4272-b263-062e07a46732"
      },
      "source": [
        "concat.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 38])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gjXI_CkPf5e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TwgCaRKPteS",
        "colab_type": "code",
        "outputId": "994c5ed8-9fff-4ea0-850b-b91b4fb10565",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.7739 - val_loss: 0.5604\n",
            "Epoch 2/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.6525 - val_loss: 0.4929\n",
            "Epoch 3/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.5515 - val_loss: 0.6696\n",
            "Epoch 4/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4698 - val_loss: 0.4335\n",
            "Epoch 5/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4466 - val_loss: 0.5220\n",
            "Epoch 6/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4445 - val_loss: 0.3962\n",
            "Epoch 7/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.8421 - val_loss: 0.3988\n",
            "Epoch 8/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4227 - val_loss: 0.3904\n",
            "Epoch 9/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4081 - val_loss: 0.3840\n",
            "Epoch 10/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.6518 - val_loss: 0.3876\n",
            "Epoch 11/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3886 - val_loss: 0.3714\n",
            "Epoch 12/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3846 - val_loss: 0.3696\n",
            "Epoch 13/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3897 - val_loss: 0.3621\n",
            "Epoch 14/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3736 - val_loss: 0.3780\n",
            "Epoch 15/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.5096 - val_loss: 0.3568\n",
            "Epoch 16/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3670 - val_loss: 0.3529\n",
            "Epoch 17/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3714 - val_loss: 0.3563\n",
            "Epoch 18/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3593 - val_loss: 0.3476\n",
            "Epoch 19/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3707 - val_loss: 0.3618\n",
            "Epoch 20/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3523 - val_loss: 0.3542\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sOYGMoqPvcI",
        "colab_type": "code",
        "outputId": "9fde21a8-3c13-4f7c-b12d-1584b4ea9b31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "mse_test = model.evaluate(X_test, y_test)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "162/162 [==============================] - 0s 2ms/step - loss: 0.3930\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86F0PGKFP2QN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_new = X_test[:3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOBnWcHzP5Xq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(X_new)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xH4GPjOoaz7p",
        "colab_type": "text"
      },
      "source": [
        "**MULTIPLE INPUT**\n",
        "But what if you want to send a subset of the features through the wide path and a different subset (possibly overlapping) through the deep path (see Figure 10-15)? In this case, one solution is to use multiple inputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2ZoOFPoa1D0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_A = keras.layers.Input(shape=[5], name=\"wide_input\") \n",
        "input_B = keras.layers.Input(shape=[6], name=\"deep_input\") \n",
        "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B) \n",
        "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1) \n",
        "concat = keras.layers.concatenate([input_A, hidden2]) \n",
        "output = keras.layers.Dense(1, name=\"output\")(concat) \n",
        "model = keras.Model(inputs=[input_A, input_B], outputs=[output])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOrwTPD9a7LG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBjbknrcbUAD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "bed1015e-dc47-41b1-81b3-a76c2f4d566e"
      },
      "source": [
        "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:] \n",
        "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:] \n",
        "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:] \n",
        "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
        "history = model.fit((X_train_A, X_train_B), y_train, epochs=20, validation_data=((X_valid_A, X_valid_B), y_valid))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 1.9171 - val_loss: 0.9428\n",
            "Epoch 2/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.8051 - val_loss: 0.7110\n",
            "Epoch 3/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.6700 - val_loss: 0.6261\n",
            "Epoch 4/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.6114 - val_loss: 0.5821\n",
            "Epoch 5/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.5772 - val_loss: 0.5559\n",
            "Epoch 6/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.5543 - val_loss: 0.5299\n",
            "Epoch 7/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.5380 - val_loss: 0.5146\n",
            "Epoch 8/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.5256 - val_loss: 0.5037\n",
            "Epoch 9/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.5163 - val_loss: 0.4951\n",
            "Epoch 10/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.5090 - val_loss: 0.4899\n",
            "Epoch 11/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.5032 - val_loss: 0.4825\n",
            "Epoch 12/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4983 - val_loss: 0.4792\n",
            "Epoch 13/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4937 - val_loss: 0.4736\n",
            "Epoch 14/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4901 - val_loss: 0.4731\n",
            "Epoch 15/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4859 - val_loss: 0.4665\n",
            "Epoch 16/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4836 - val_loss: 0.4638\n",
            "Epoch 17/20\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4798 - val_loss: 0.4681\n",
            "Epoch 18/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4767 - val_loss: 0.4571\n",
            "Epoch 19/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4739 - val_loss: 0.4572\n",
            "Epoch 20/20\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.4709 - val_loss: 0.4563\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpMrdO4KbjTn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5bb97b92-707d-42ff-f2c9-67c82a26c52b"
      },
      "source": [
        "mse_test = model.evaluate((X_test_A, X_test_B), y_test) \n",
        "y_pred = model.predict((X_new_A, X_new_B))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "162/162 [==============================] - 0s 2ms/step - loss: 0.4931\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R14ZQNzJcq0N",
        "colab_type": "text"
      },
      "source": [
        "**AUXILARY OUTPUT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHbFLpFlcqC2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output = keras.layers.Dense(1, name=\"main_output\")(concat) \n",
        "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2) \n",
        "model = keras.Model(inputs=[input_A, input_B], outputs=[output, aux_output])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QU7c44rddJ2z",
        "colab_type": "text"
      },
      "source": [
        "Each output will need its own loss function.\n",
        "we want to give the main outputâ€™s loss a much greater weight"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5Z9S54vdH1H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=\"sgd\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEpX5x2adV5n",
        "colab_type": "text"
      },
      "source": [
        "Now when we train the model, we need to provide labels for each output. In this example, the main output and the auxiliary output should try to predict the same thing, so they should use the same labels. So instead of passing y_train, we need to pass (y_train, y_train) (and the same goes for y_valid and y_test):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJNiQbysdUWc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "5c1cedea-ee9b-4ece-d047-8497791fb2a2"
      },
      "source": [
        "history = model.fit( [X_train_A, X_train_B], [y_train, y_train], epochs=20, validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.7640 - main_output_loss: 0.6544 - aux_output_loss: 1.7504 - val_loss: 0.5509 - val_main_output_loss: 0.4983 - val_aux_output_loss: 1.0243\n",
            "Epoch 2/20\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.5784 - main_output_loss: 0.5366 - aux_output_loss: 0.9546 - val_loss: 0.5085 - val_main_output_loss: 0.4693 - val_aux_output_loss: 0.8613\n",
            "Epoch 3/20\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.5139 - main_output_loss: 0.4788 - aux_output_loss: 0.8295 - val_loss: 0.4757 - val_main_output_loss: 0.4426 - val_aux_output_loss: 0.7735\n",
            "Epoch 4/20\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.4954 - main_output_loss: 0.4666 - aux_output_loss: 0.7553 - val_loss: 0.4640 - val_main_output_loss: 0.4355 - val_aux_output_loss: 0.7207\n",
            "Epoch 5/20\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.4801 - main_output_loss: 0.4548 - aux_output_loss: 0.7080 - val_loss: 0.4539 - val_main_output_loss: 0.4278 - val_aux_output_loss: 0.6892\n",
            "Epoch 6/20\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.4615 - main_output_loss: 0.4373 - aux_output_loss: 0.6789 - val_loss: 0.4491 - val_main_output_loss: 0.4248 - val_aux_output_loss: 0.6680\n",
            "Epoch 7/20\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.4528 - main_output_loss: 0.4299 - aux_output_loss: 0.6598 - val_loss: 0.4297 - val_main_output_loss: 0.4052 - val_aux_output_loss: 0.6498\n",
            "Epoch 8/20\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.4466 - main_output_loss: 0.4245 - aux_output_loss: 0.6453 - val_loss: 0.4572 - val_main_output_loss: 0.4362 - val_aux_output_loss: 0.6465\n",
            "Epoch 9/20\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.4389 - main_output_loss: 0.4175 - aux_output_loss: 0.6314 - val_loss: 0.4169 - val_main_output_loss: 0.3937 - val_aux_output_loss: 0.6256\n",
            "Epoch 10/20\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.4321 - main_output_loss: 0.4111 - aux_output_loss: 0.6209 - val_loss: 0.4114 - val_main_output_loss: 0.3888 - val_aux_output_loss: 0.6145\n",
            "Epoch 11/20\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.4258 - main_output_loss: 0.4052 - aux_output_loss: 0.6109 - val_loss: 0.4087 - val_main_output_loss: 0.3869 - val_aux_output_loss: 0.6050\n",
            "Epoch 12/20\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.4185 - main_output_loss: 0.3984 - aux_output_loss: 0.5994 - val_loss: 0.4158 - val_main_output_loss: 0.3956 - val_aux_output_loss: 0.5980\n",
            "Epoch 13/20\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.4143 - main_output_loss: 0.3946 - aux_output_loss: 0.5912 - val_loss: 0.4015 - val_main_output_loss: 0.3803 - val_aux_output_loss: 0.5929\n",
            "Epoch 14/20\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.4102 - main_output_loss: 0.3909 - aux_output_loss: 0.5840 - val_loss: 0.3987 - val_main_output_loss: 0.3783 - val_aux_output_loss: 0.5818\n",
            "Epoch 15/20\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.4041 - main_output_loss: 0.3854 - aux_output_loss: 0.5721 - val_loss: 0.3860 - val_main_output_loss: 0.3660 - val_aux_output_loss: 0.5659\n",
            "Epoch 16/20\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.3983 - main_output_loss: 0.3800 - aux_output_loss: 0.5630 - val_loss: 0.3806 - val_main_output_loss: 0.3609 - val_aux_output_loss: 0.5581\n",
            "Epoch 17/20\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.3984 - main_output_loss: 0.3806 - aux_output_loss: 0.5586 - val_loss: 0.3855 - val_main_output_loss: 0.3666 - val_aux_output_loss: 0.5555\n",
            "Epoch 18/20\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.3921 - main_output_loss: 0.3748 - aux_output_loss: 0.5477 - val_loss: 0.3827 - val_main_output_loss: 0.3650 - val_aux_output_loss: 0.5424\n",
            "Epoch 19/20\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.3856 - main_output_loss: 0.3687 - aux_output_loss: 0.5377 - val_loss: 0.3748 - val_main_output_loss: 0.3568 - val_aux_output_loss: 0.5369\n",
            "Epoch 20/20\n",
            "363/363 [==============================] - 2s 5ms/step - loss: 0.3811 - main_output_loss: 0.3641 - aux_output_loss: 0.5337 - val_loss: 0.3678 - val_main_output_loss: 0.3500 - val_aux_output_loss: 0.5281\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysMTcghQdc6r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1e712ebf-d46b-47bc-eec9-ecfe7da4f30c"
      },
      "source": [
        "total_loss, main_loss, aux_loss = model.evaluate( [X_test_A, X_test_B], [y_test, y_test])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "162/162 [==============================] - 0s 3ms/step - loss: 0.3930 - main_output_loss: 0.3774 - aux_output_loss: 0.5331\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxrIfK5ddkTV",
        "colab_type": "text"
      },
      "source": [
        "When we evaluate the model, Keras will return the total loss, as well as all the individual losses:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_upx0C6df7z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}